데이터를 부탁해 / 전익진 지음 한빛미디어

오랜만에 분산,표준편차 등 고등학교때 확률과 통계에서 배웠던 것들을 다시 상기시키는 계기가 되었다. 그리고 데이터 분석도 무작정 하는 것이 아닌, 방법이 다 있다는 것이다.

1. 데이터-기생충을 비유한것이 인상에 깊었다.
기생충의 핵심은 '숙주' 우수한 숙주를 만나야 '번식'이라는 큰 뜻을 이룰 수 있다.

데이터도 훌륭한 숙주(사람)을 만나야 큰 가치를 전달할 수 있다. 데이터는 누구에게 분석되고 해석되느냐에 따라 결과를 달리하는 매우 유연한 무생물이다. 기생충도, 데이터도 동서고금을 막론하고 어디에든 존재한다.

2. 데이터분석은 그들만의 리그가 아닌, 모두가 이해하고 인정하는 보편적인 영역이 되어야 더욱 발전하고 더 전문적인 영역으로 인정받을 수 있다.

데이터분석을 통해 스스로 판단하고 결정해 실행하는 시대가 왔다.
데이터의 흐름은 데이터>정보>지식>지혜
4. 평균 편차 분산 표준편차
평균은 일반적으로 '산술평균'을 이야기한다. 산술평균은 주어진 수의 합을 수의 개수로 나눈 값. 평균은 수식이 간단해서
다양한 분야에서 폭넓게 사용된다.
평균은 극단적인 값에 민감하다. 평균을 진정한 평균으로 만들 방법이 필요하다.

계산한 평균으로부터 각각의 관측 값(ex.과목별 점수)이 얼마나 멀리 떨어져 있는지를 측정. 관측값들이 평균으로부터
얼마나 떨어져 분포돼 있는지를 확인하는 것을 '편차'라고 한다.
편차는 양수와 음수 둘 다 존재한다. 관측 값이 평균보다 높을 수도 있고, 낮을 수도 있기 때문이다.
편차를 모두 더하면 반드시 0이 된다. 편차의 평균도 0이므로 편차로 평균의 대표성을 가늠하기 쉽지 않다.
편차의 합이 0이 되지 않는 방법이 필요하다. (편차가 모두 음수거나 양수면 합이 0이 되지 않는다) 음x음수 = 양수
각 편차를 제곱해 원라의 편차 값을 두 배로 늘린다. 두 배로 늘린 편차의 평균을 '분산'이라고 한다. 분산은 편차제곱/표본의 개수
제곱으로 구한 분산은 그 값이 두 배로 늘었으므로 다시 줄이는 과정이 필요하다. 제곱근(루트)을 취하는데 이를 표준편차라고 한다.
평균을 제시할 때는 반드시 표준편차를 함께 이야기해야 한다. 그래야만 제시된 평균이 얼마나 신뢰성 있는 가치인지를 판단 가능하다. 평균을 올리는 것만큼 표준편차를 줄이려는 노력이 필요하다.

대부분 분야에서 데이터분석 시 분석보다는 표본조사를 수행한다. (ex.선거) 전체에서 선택된 표본은 매우 중요하다. 언론사는 일부 선택된 유권자를 표본으로 삼아 전체를 예측한다.

어떤 확률을 구하기 위해 실험과 관찰 횟수가 많아지면 얻고자 하는 확률을 수렴할 것이다.

8. 데이터분석은 표본을 통해 전체를 이해해야 하므로 전체로부터 표본을 선택하는 과정이 매우 중요하다. 순서를 고려하지 않는방법을 무작위 추출이라고 한다.

9. 중심극한정리
중심극한정리는 모집단의 규모가 클수록 해당 모집단의 평균을 미리 알기가 어렵다. 그래서 표본을 추출하여 분석하는데 모집단에서 추출한 표본 평균은 모집단의 평균을 기준으로 좌우 대칭으로 분포되어있다. 이는 모집단의 평균이 무엇이든 상관없이 모집단으로부터 추출한 여러 표본의 각 평균은 모집단의 평균을 중심으로 좌우 대칭 형태로 분포된다.

표본은 전체에서 추출한 '확률'이다. 표본평균의 분포를 이론적으로 설명한 중심극한정리는 확률분포에 의거하며 이러한 확률분포를 정규분포라고 한다.

10. 대립가설과 귀무가설
대립가설 : 내가 얻고자 하는 상황 설정
귀무가설 : 얻고자 하는 진실과는 반대의 상황 설정 (ex. 담배는 폐암을 유발한다를 증명하려면, 그 반대 가설인 담배는 폐암을 유발하지 않는다 라는 것을 거짓임을 증명함으로써 담배가 폐암을 유발하는 원인임을 증명한다.)
데이터분석시에도 일반적으로 귀무가설을 세우고 해당 가설이 틀렸다는 것을 증명해 본인의 이론을 논리적으로 확정

11. 유의수준
유의수준(pvalue=p) 가설에 대한 검정 결과가 ex 잘못될 가능성을 5%, 신뢰할 수 있는 수준을 95%으로 설정하여 유의수준의 값이 낮으면 낮을수록 해당 검정 결과는 더욱 정밀해지며 결과 신뢰도 높아진다. 오류를 방지하기 위해 경계선을 정한 것이다.

12. t-검정과 z-검정
t-검정 : 두 집단 간에 평균의 차이가 있는지를 비교하는 검증. 유의수준과 유의확률 내에서 분석한 내용이 포함되는지를 확인. 표본을 무작위로 선정했을 때 차이가 날 확률이 몇 %인지를 검증하는 작업
z-검정 : 정규분포를 따르는 가설을 검정. 데이터의 양이 많으면 많을수록 평균값의 차이가 정규분포를 따른다는 의미. 대용량의 데이터에서 통계를 검정할 때 사용한다.

13. 회귀분석 by 프랜시스 골턴
키가 큰 아버지는 그보다 조금 작은 자식을, 키가 작은 아버지는 그보다 조금 큰 자식을 갖게 된다는 결과(평균으로부터의 회귀) 모든 현상이 평균적으로 회귀하려는 사실에 기초(회귀분석) 회귀는 원래 상태로 돌아온다는 뜻

14. 독립변수와 종속변수
독립변수 : 예측하고자 하는 결과의 원인으로 가정한 '변수'
종속변수 : 독립변수가 원인이 돼 예측할 수 있는 결괏값
ex) 독립변수는 아버지 키, 종속변수는 아들 키. 회귀분석으로 예측하려면 독립변수와 종속변수의 상관관계가 명확해야 한다.

15. 칼 피어슨
통계학의 기초를 정립한 수학자.
피어슨 상관계수는 -1~+1 사이의 값을 취한다. 0을 기준으로 0보다 작은 음수는 음의 상관관계를 가지며, 0보다 큰 양수는 양의 상관관계. 두 변이 간에 관계가 있다.

16. 확률분포
이산확률분포(베르누이분포-성공과 실패의 두 가지의 값(0,1)만으로 확률분표 표현, 이항분포, 포아송분포)가 있으며 연속확률분포에는 (균등분포,정규분포,지수분포)가 있다.

17. t-검정은 두 집단의 검정만 가능하며, 2개 이상의 집단을 비교 검정할 때는 분산분석을 수행한다.

18. 찰스 스피어만(심리학자)
특정 범주에 속한 인간의 세부 능력 간에는 연관성이 매우 높다.
ex) 언어 능력이 뛰어난 사람의 세부 능력을 보면 어휘 능력치가 높은 사람은 같은 범주 내에 있는 작문,독해 능력이 뛰어나다. 그러나 다른 범주와의 비교에서 언어 능력치가 높은 사람들은 수리 능력이나 그 외의 범주에 속하는 능력치가 높지 않다는 점.

나인가..?

19. 모수적 검정과 비모수적 검정
모수적 검정 : 데이터가 정규분포를 따른다. 데이터가 정규분포로 표현될 만큼 표본 수가 많다. 데이터들이 같은 환경에 있다.
비모수적 검정 : 데이터가 정규분포가 아니며 데이터의 표본 수가 적거나 부족하고 데이터가 서로 독립적인 경우

20. K-NN
유사도로 데이터를 분류하고 특성에 따라 구분. 최근접 이웃 알고리즘
데이터의 속성을 파악해 가장 가까운 이웃을 묶는 데이터 분석 기법. 기존 데이터 집단이 있고, 이 데이터 집단을 특정 기준에 따라 분류하고 분류한 집단마다 명패를 부여. 새로운 데이터는 분류된 집단에서 가장 인접한 집단에 배치
K-MEANS : 거리를 통해 새로운 데이터를 분리된 군집에 추가함. n개의 데이터를 k개의 군집으로 분리해 경계선을 작성한다. 분리된 각 군집의 평균 거리를 계산하고, 군집별 중심값과 비교해 거리가 가장 가까운 것을 선택

21. 정성과 정량
정성은 상태 표현, 정량은 수치 표현

22. 시계열 분석
시간을 묶어 나열
과거 흐름이 미래 흐름과 크게 다르지 않을 것이라고 전제하고 오롯이 과거 데이터만을 활용

23. 다시 한번 회귀분석!!!
데이터분석에서 회귀분석이 매우 중요하다. 인과관계를 파악해 연속형 변수 간의 적합도를 함수식으로 구하는 예측 기법.상관관계는 기본이고 영향을 주는 독립변수와 영향을 받는 종속변수가 있어야 한다. 독립변수가 변함에 따라 종속변수가 어떤 변화를 보이는지를 설명하는 모델.
단순회귀분석은 종속변수에 영향을 주는 요인인 독립변수가 하나 y=f(x)
다중회귀분석은 y에 영향을 주는 x 독립변수 2개 이상 y=f(x1,x2)

24. 빅데이터의 요소 4V
가트너(시장조사기관)은 빅데이터의 요소를 4V로 설명
대용량데이터 Volume
빠르게 처리하는 기술 Velocity
다양한 종류의 데이터 Variety
정확성 Veracity 가변성 Variability

25. 데이터마이닝
데이터를 추출,가공하는 데이터분석을 위한 전처리 과정(보기 좋게 데이터 고치는 모든 작업)으로 '분석 대상'을 찾는 과정. 데이터마이닝은 분석 대상이 명확하다.

26. 정형데이터와 비정형데이터
정형데이터 : 미리 정해진 속성에 따라 정제해 분류된 데이터
비정형데이터 : 데이터 안에서 속성을 찾아서 의미를 새롭게 부여해야 하는 데이터. 아직 속성을 파악하지 못한 데이터

27. 자연어와 자연어 처리
자연어 : 일상에서 사용하는 언어.
자연어처리 : 자연어의 속성을 파악하는 기법. 음성과 문서를 모두 포함하며 자연어 처리를 넘어 자연어 생성 분야까지 연구가 확대되고 있다. 인공지능의 중요한 영역으로써 활발히 연구되고 있다. 어렵고 난해하며 단순히 언어적 기능과 문법의 의미, 패턴 등을 반영하는 것을 넘어 언어에 내포된 감정까지 다루어야 한다.

28. 텍스트마이닝
글로 표현된 모든 것을 파악해 그 안에 내포된 의믜와 의도, 성향 등을 구별하는 기법. 텍스트마이닝은 데이터분석기법은 아니지만 결과는 충분히 유용하다. 데이터분석을 위한 전처리로 텍스트 마이닝을 하는 경우가 많다. 텍스트마이닝이 중요한 이유는 일상에서 자연어로 의사소통을 하기 때문
